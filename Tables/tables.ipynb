{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75d4a215-9dcb-437a-8418-5f8c9a1b7ab5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Processing and analysis of data for meteor detection\n",
    "## TABLES - Setting up the working environment for data tables creating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81eb87-d004-4264-9213-355848f03b67",
   "metadata": {},
   "source": [
    "This command is used to install the Python packages matplotlib and pandas, which are commonly used for data visualization and data manipulation tasks, respectively.\n",
    "\n",
    "NOTE: The package \"opencv-python\" is already included in the previous installation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59f1dda-0e09-4736-9054-8db64ed7ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec2bb3c-6e90-4724-a3f2-7413b9075c8a",
   "metadata": {},
   "source": [
    "These import statements bring in various Python libraries/modules needed for the subsequent code execution. Each import statement brings in specific functionality from the corresponding library/module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa588c53-6153-4cae-ba0b-332a86c63736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math \n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "from IPython.display import Image, clear_output\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image, ImageDraw\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from sys import path\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6841823-435c-4024-b123-b34ff4142b3e",
   "metadata": {},
   "source": [
    "Next code defines variables related to paths for image and text files used in testing. \n",
    "\n",
    "imagePath: Represents the directory path to the testing images along with their corresponding text files.\n",
    "\n",
    "route: Refers to a specific route or directory within the Ultralytics structure.\n",
    "\n",
    "rootPath: Constructs the root path for the labels based on the provided route.\n",
    "\n",
    "path: Indicates the general path to the Ultralytics directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeace00-7e52-49ac-9589-3170301331a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath=\"data/lightning/Kamila/testovacia\"       \n",
    "route=\"ALL_704_c10iou10_ult_train_final\"\n",
    "rootPath = r\"ultralytics/runs/detect/predict/\" + route + \"/labels\"\n",
    "path = \"ultralytics\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f2d0e0-77c1-4627-bbd6-2a830cc09ec3",
   "metadata": {},
   "source": [
    "This code is responsible for parsing label files associated with images, extracting useful information from them, and storing that information in a structured format in these steps:\n",
    "\n",
    "1. Defines paths to directories containing image and label files.\n",
    "2. Creates a CSV file named 'testing5.csv' to store extracted information.\n",
    "3. Reads through each label file in the specified directory.\n",
    "4. Processes the content of each label file to extract relevant information such as event name, label, coordinates, width, height, confidence, duration, and date.\n",
    "5. Writes the extracted information into the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c01e40-024e-46d3-86ba-1226c8d2b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cesta = os.getcwd() + \"/ultralytics/runs/detect/predict/ALL_704_c10iou10_ult_train_final\"\n",
    "tab_cesta = os.getcwd() + \"/ultralytics/runs/detect/predict/ALL_704_c10iou10_ult_train_final/labels\"\n",
    "name = [f for f in listdir(tab_cesta) if isfile(join(tab_cesta, f))]\n",
    "csvOut = 'testing5.csv'\n",
    "path = '/ultralytics/runs/detect/predict/ALL_704_c10iou10_ult_train_final/labels'\n",
    "\n",
    "import csv\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "\n",
    "with open(csvOut, mode='w') as csv_file:\n",
    "    fieldnames = ['event name', 'label', 'x', 'y', 'width', 'height', 'confidence', 'length_in_sec', 'picture_ends_in', 'date']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for root, dirs, files in os.walk(tab_cesta):\n",
    "        for name in files:\n",
    "            file = os.getcwd() + path + \"/\" + name\n",
    "            print(file)\n",
    "            with open(file) as f:\n",
    "                meno = os.path.splitext(name)[0]\n",
    "                lines = f.readlines()\n",
    "                dlzka = len(lines)\n",
    "                i = 0\n",
    "                while i < dlzka:\n",
    "                    try:\n",
    "                        image1 = Image.open(os.path.join(img_cesta, name.split(\".\")[0] + \".jpg\"))\n",
    "                        image2 = (os.path.join(img_cesta, name.split(\".\")[0])).split(\"/\")[11].split(\"_\")[1]\n",
    "                        image3 = (os.path.join(img_cesta, name.split(\".\")[0])).split(\"/\")[11].split(\"_\")[0]\n",
    "                    except:\n",
    "                        break\n",
    "                    line = lines[i]\n",
    "                    splitted = line.split(\" \")\n",
    "                    list(map(lambda x: x.strip(), splitted))\n",
    "                    length = round((float(splitted[3]) * (image1.size[0]) * (5 / 168.5)), 4)\n",
    "                    begins = image2[0:2] + \":\" + image2[2:4] + \":\" + image2[4:6]\n",
    "                    date = image3[11:] + \".\" + image3[9:11] + \".\" + image3[5:9]\n",
    "                    if int(splitted[0]) == 0:\n",
    "                        a = \"kr치tka bez headecha\"\n",
    "                    if int(splitted[0]) == 1:\n",
    "                        a = \"kr치tka s headechom\"\n",
    "                    if int(splitted[0]) == 2:\n",
    "                        a = \"dlh치 bez headecha\"\n",
    "                    if int(splitted[0]) == 3:\n",
    "                        a = \"dlh치 s headechom\"\n",
    "                    writer.writerow({\n",
    "                        'event name': meno,\n",
    "                        'label': a,\n",
    "                        'x': splitted[1],\n",
    "                        'y': splitted[2],\n",
    "                        'width': splitted[3],\n",
    "                        'height': splitted[4],\n",
    "                        'confidence': splitted[5],\n",
    "                        'length_in_sec': length,\n",
    "                        'picture_ends_in': begins,\n",
    "                        'date': date})\n",
    "                    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4389aa9-d193-4f60-a6e8-fb008bd6bd70",
   "metadata": {},
   "source": [
    "This code ensures that only unique detections are retained in the dataset by removing any duplicate entries based on specified conditions in these steps:\n",
    "\n",
    "1. It reads the contents of a CSV file named 'testing5.csv'.\n",
    "2. It compares each row with every other row in the CSV file to identify duplicates.\n",
    "3. If two rows are considered duplicates based on specified criteria (e.g., similar coordinates and event name), it keeps the row with the higher confidence score.\n",
    "4. It writes the non-duplicate rows to a new CSV file named 'testing5_1.csv', effectively removing duplicates from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36604927-0cfd-4759-a2d3-22f43916aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csvfile = 'testing5.csv'\n",
    "lines2=list()\n",
    "zhoda=False\n",
    "\n",
    "with open(csvfile, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = []\n",
    "    header = next(reader)\n",
    "    lines2.append(header)\n",
    "    for row in reader:\n",
    "        zhoda=False\n",
    "        for compare_row in reader:\n",
    "            if(row!=compare_row):\n",
    "                if((float(row[2])-0.15 <= float(compare_row[2])) and (float(row[2])+0.15 >= float(compare_row[2])) and (float(row[3])-0.1 <= float(compare_row[3])) and (float(row[3])+0.1 >= float(compare_row[3])) and (row[0]==compare_row[0])):     \n",
    "                    if((row[6])>(compare_row[6])):\n",
    "                        lines2.append(row)\n",
    "                    elif((row[6])<(compare_row[6])):\n",
    "                        lines2.append(compare_row)\n",
    "                    zhoda=True\n",
    "            break\n",
    "        if (zhoda==False):\n",
    "            lines2.append(row)\n",
    "            lines2.append(compare_row)\n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "with open('testing5_1.csv', 'w', newline='') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82abd07e-5a1d-410b-af04-69f2d6f93fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
